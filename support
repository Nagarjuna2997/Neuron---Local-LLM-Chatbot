# Neuron

**Your Local LLM Chatbot**
Minimal. Smart. On-Device.

Neuron is an iOS app that runs AI language models entirely on your iPhone. No cloud. No APIs. No internet required for chat. Download a model, load it, and start a conversation — everything stays on your device.

---

## Why Neuron

Most AI chat apps require a subscription or send your data to external servers. Neuron does neither. It runs open-source language models directly on your iPhone using Metal GPU acceleration. Your conversations and personal data never leave your device.

---

## Features

**On-Device Inference**
All AI processing happens locally on your iPhone. No server calls. No internet dependency for chat.

**Model Hub**
Browse and download models from a curated catalog of open-weight LLMs including Llama, Phi, Qwen, Gemma, Mistral, and SmolLM families. Each model displays file size, parameter count, and a device compatibility indicator before download.

**Chat**
Clean chat interface with real-time streaming responses. Conversations are saved locally and can be continued anytime.

**Memory**
Neuron remembers details you share across conversations — your name, preferences, interests, and any personal context. All memory is stored locally. View and delete memory entries at any time.

**Folders**
Optionally organize conversations into folders. Create, rename, and delete folders as needed.

**Privacy**
No accounts. No analytics. No tracking. No data collection. Everything stays on your iPhone.

---

## Supported Models

| Family | Models | Size Range |
|--------|--------|------------|
| Llama | 3.2 1B, 3.2 3B, 3.1 8B | 0.7 - 4.7 GB |
| Phi | 3.5 Mini, 4 Mini | 2.2 - 2.4 GB |
| Qwen | 2.5 0.5B, 1.5B, 3B, 7B | 0.4 - 4.4 GB |
| Gemma | 2 2B | 1.5 GB |
| Mistral | 7B v0.3 | 4.1 GB |
| SmolLM | 360M, 1.7B | 0.3 - 1.0 GB |

All models are in GGUF format and available through Hugging Face.

---

## Device Compatibility

Neuron detects your iPhone model and shows compatibility before you download any model.

- **iPhone 12 and newer** — Runs small models (under 2GB) smoothly
- **iPhone 13 and newer** — Runs small and medium models (under 4GB) well
- **iPhone 15 Pro and newer** — Runs all models including large 7B+ models

---

## Tech Stack

- Swift & SwiftUI
- SwiftData for local persistence
- llama.cpp for on-device inference
- Metal GPU acceleration
- GGUF model format

---

## Requirements

- iOS 17.0 or later
- iPhone 12 or newer recommended
- Storage space for downloaded models (varies by model)

---

## Build From Source

1. Clone the repository
```
git clone https://github.com/Nagarjuna2997/Neuron.git
cd Neuron
```

2. Add llama.cpp dependency
   - See `LLAMA_CPP_SETUP.md` for step-by-step integration instructions

3. Open `Neuron.xcodeproj` in Xcode

4. Select your target device and build

---

## Project Structure

```
Neuron/
├── App/
│   └── NeuronApp.swift
├── Models/
│   ├── ChatConversation.swift
│   ├── ChatMessage.swift
│   ├── ChatFolder.swift
│   ├── MemoryEntry.swift
│   └── LLMModelInfo.swift
├── Views/
│   ├── ContentView.swift
│   ├── ModelsTab/
│   ├── ChatsTab/
│   ├── FoldersTab/
│   └── SettingsTab/
├── Services/
│   ├── LLMManager.swift
│   ├── MemoryManager.swift
│   └── ModelDownloader.swift
├── Bridge/
│   └── llama-bridge.h
└── Resources/
    └── ModelCatalog.json
```

---

## Privacy

Neuron does not collect, transmit, or store any user data on external servers. All conversations, memory entries, and model files are stored locally on the user's device. No analytics. No tracking. No accounts required.

---

## License

MIT License. See `LICENSE` for details.

---

## Contact

- GitHub: [github.com/Nagarjuna2997](https://github.com/Nagarjuna2997)
- LinkedIn: [linkedin.com/in/nagarjuna-reddy-97836a193](https://linkedin.com/in/nagarjuna-reddy-97836a193)

---

## Acknowledgments

- [llama.cpp](https://github.com/ggerganov/llama.cpp) for on-device inference
- [Hugging Face](https://huggingface.co) for hosting open-weight models
- Open-source model creators: Meta, Microsoft, Alibaba, Google, Mistral AI, Hugging Face
